<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="A benchmark for detecting LLM biases on NLU tasks in AAVE.">
  <meta name="keywords" content="AAVENUE, Benchmark, LLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AAVENUE: Detecting LLM Biases on NLU Tasks in AAVE via a Novel Benchmark</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    .shiny-button {
      background: #333;
      border: 1px solid #444;
      border-radius: 5px;
      color: #fff;
      cursor: pointer;
      display: inline-flex;
      align-items: center;
      font-size: 16px;
      padding: 10px 20px;
      text-align: center;
      text-decoration: none;
      position: relative;
      overflow: hidden;
      transition: all 0.3s ease;
      font-family: Arial, sans-serif;
    }

    .shiny-button .icon {
      margin-right: 8px;
    }

    .shiny-button::before {
      content: '';
      position: absolute;
      top: 50%;
      left: 50%;
      width: 300%;
      height: 300%;
      background: radial-gradient(circle, rgba(255, 255, 255, 0.2) 0%, rgba(255, 255, 255, 0) 60%);
      transition: all 0.3s ease;
      transform: translate(-50%, -50%) scale(0);
      border-radius: 50%;
      z-index: 0;
    }

    .shiny-button:hover::before {
      transform: translate(-50%, -50%) scale(1);
    }

    .shiny-button span {
      position: relative;
      z-index: 1;
    }
  </style>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="http://aavenue.live/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>
      </div>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AAVENUE: Detecting LLM Biases on NLU Tasks in AAVE via a Novel Benchmark</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://www.linkedin.com/in/abhaygupta12/">Abhay Gupta</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/philip-meng-1402b0258/">Philip Meng</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/ece-yurtseven-b61b68259/">Ece Yurtseven</a><sup>3</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>John Jay Senior High School,</span>
              <span class="author-block"><sup>2</sup>Phillips Academy,</span>
              <span class="author-block"><sup>3</sup>Robert College</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/abhayg1266/AAVENUE-Code" class="shiny-button">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

              <section class="section">
                <div class="container is-max-desktop">
                  <!-- Abstract. -->
                  <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                      <h2 class="title is-3">Abstract</h2>
                      <div class="content has-text-justified">
                        <p>
                          Detecting biases in natural language understanding (NLU) for African American Vernacular English (AAVE) is
                          crucial for developing inclusive natural language processing (NLP) systems. Dialect differences lead to
                          performance discrepancies in language technologies, posing challenges for inclusive NLP, which aims to
                          ensure consistent performance across dialectal variations. To address these challenges, we introduce
                          <b>AAVENUE</b> (<b>AAVE</b> <b>N</b>atural Language <b>U</b>nderstanding <b>E</b>valuation), a benchmark designed to evaluate large language
                          model (LLM) performance on standard NLU tasks across AAVE and Standard American English (SAE). Existing
                          benchmarks like VALUE address dialectal bias using deterministic linguistic transformations to evaluate
                          AAVE performance, but these often lack generalizability, limiting their broader applicability. We
                          construct our dataset by using GPT-4-turbo to translate a subset of key tasks from the GLUE and SuperGLUE
                          benchmarks from SAE to AAVE. To validate the quality of our translations, we conducted direct comparison
                          tests against translations generated by VALUE, using fluency scores and BARTScore for translation quality.
                          Our findings showed that our translations were preferred across five popular LLMs. Finally, our
                          evaluations demonstrate that LLMs consistently achieve higher accuracy on SAE versions of NLU tasks
                          compared to AAVE-translated versions, highlighting significant biases in model performance. These findings
                          underscore the need for more inclusive NLP models.
                        </p>
                      </div>
                    </div>
                  </div>
                  <!--/ Abstract. -->
                </div>
              </section>

              <!-- Methodology Section -->
              <section class="section">
                <div class="container is-max-desktop">
                  <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                      <h2 class="title is-4">Methodology & Data</h2>
                      <div class="content has-text-justified">
                        <p>
                          Our research introduces AAVENUE, a novel benchmark designed to assess the performance of large language models on natural language understanding tasks across AAVE and SAE dialects. Our methodology involves translating tasks from existing benchmarks into AAVE using GPT-4-turbo, followed by comprehensive evaluations using various language models.
                        </p>
                        <p>
                          We selected key tasks from the GLUE and SuperGLUE benchmarks, which are well-regarded for evaluating language model performance across a range of linguistic challenges. The tasks chosen for this study include:
                        </p>
                        <ul>
                          <li><b>SST-2:</b> Sentiment Analysis</li>
                          <li><b>BoolQ:</b> Question Answering</li>
                          <li><b>COPA:</b> Causal Reasoning</li>
                          <li><b>WSC:</b> Coreference Resolution</li>
                          <li><b>MultiRC:</b> Reading Comprehension</li>
                        </ul>
                        <p>
                          We utilized zero-shot prompting to generate AAVE translations, which were then evaluated using fluency scores and BARTScore metrics. Our analysis included a comprehensive set of 1000 data points per task, ensuring robust evaluation.
                        </p>
                        <table class="table is-bordered is-striped is-narrow is-fullwidth">
                          <thead>
                            <tr>
                              <th>Task</th>
                              <th>SAE Example</th>
                              <th>AAVE Example</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td>SST-2</td>
                              <td>The movie was preachy and poorly acted.</td>
                              <td>Ain't much to like, it be preachy and acted bad.</td>
                            </tr>
                            <tr>
                              <td>BoolQ</td>
                              <td>Can I be sacked for falling asleep at work?</td>
                              <td>Can I get fired for fallin' asleep on the job?</td>
                            </tr>
                            <tr>
                              <td>COPA</td>
                              <td>Man lost the competition. Choice 1: The competition was sabotaged. Choice 2: He intimidated his competitors. (Selected: Choice 1)</td>
                              <td>Man lost da competition. Choice 1: Da competition got messed up. Choice 2: He scared off his competitors. (Selected: Choice 1)</td>
                            </tr>
                            <tr>
                              <td>WSC</td>
                              <td>Sam Goodman's biography of the Spartan general Xenophanes shows the difficulties he faced in his childhood.</td>
                              <td>Sam Goodman's biography on that Spartan general Xenophanes show y'all the tough times he had growin' up.</td>
                            </tr>
                            <tr>
                              <td>MultiRC</td>
                              <td>Paragraph: A stranger in town... How does Jason react to the stranger's presence?</td>
                              <td>Paragraph: A stranger in town... How Jason be actin' to that stranger around?</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                    </div>
                  </div>
                </div>
              </section>
              <!--/ Methodology Section -->

              <!-- Results Section -->
              <section class="section">
                <div class="container is-max-desktop">
                  <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                      <h2 class="title is-4">Results</h2>
                      <div class="content has-text-justified">
                        <p>
                          Our results demonstrate the performance discrepancies between SAE and AAVE translations across various language models. The analysis revealed that language models consistently perform better on SAE tasks compared to AAVE, indicating inherent biases in these models.
                        </p>
                        <p>
                          The following tables summarize the accuracy scores and comparison metrics used to evaluate the models:
                        </p>
                        <table class="table is-bordered is-striped is-narrow is-fullwidth">
                          <thead>
                            <tr>
                              <th>Task</th>
                              <th>Model</th>
                              <th>SAE Accuracy</th>
                              <th>AAVE Accuracy</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td>SST-2</td>
                              <td>GPT-3.5-turbo</td>
                              <td>93.5%</td>
                              <td>89.5%</td>
                            </tr>
                            <tr>
                              <td>BoolQ</td>
                              <td>GPT-3.5-turbo</td>
                              <td>81.8%</td>
                              <td>82.5%</td>
                            </tr>
                            <tr>
                              <td>COPA</td>
                              <td>GPT-3.5-turbo</td>
                              <td>68.8%</td>
                              <td>67.6%</td>
                            </tr>
                            <tr>
                              <td>WSC</td>
                              <td>GPT-3.5-turbo</td>
                              <td>50.2%</td>
                              <td>48.2%</td>
                            </tr>
                            <tr>
                              <td>MultiRC</td>
                              <td>GPT-3.5-turbo</td>
                              <td>70.1%</td>
                              <td>62.0%</td>
                            </tr>
                          </tbody>
                        </table>

                        <table class="table is-bordered is-striped is-narrow is-fullwidth">
                          <thead>
                            <tr>
                              <th>Model</th>
                              <th>Task</th>
                              <th>AAVE/Value/Same</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td>GPT-3.5-turbo</td>
                              <td>SST-2</td>
                              <td>64.66/30.15/5.20</td>
                            </tr>
                            <tr>
                              <td>GPT-4-turbo</td>
                              <td>SST-2</td>
                              <td>65.90/17.15/16.94</td>
                            </tr>
                            <tr>
                              <td>GPT-4o</td>
                              <td>BoolQ</td>
                              <td>77.61/21.02/1.37</td>
                            </tr>
                            <tr>
                              <td>Gemini-1.5-flash</td>
                              <td>BoolQ</td>
                              <td>75.77/22.07/2.17</td>
                            </tr>
                            <tr>
                              <td>Gemini-1.5-pro</td>
                              <td>WSC</td>
                              <td>78.73/20.32/0.95</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                    </div>
                  </div>
                </div>
              </section>
              <!--/ Results Section -->

              <!-- Limitations Section -->
              <section class="section">
                <div class="container is-max-desktop">
                  <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                      <h2 class="title is-4">Limitations</h2>
                      <div class="content has-text-justified">
                        <p>
                          Despite our comprehensive approach, there are several limitations to this study. One key limitation is the reliance on zero-shot prompting for translations, which may introduce biases inherent in the models themselves. Additionally, the benchmark primarily focuses on a limited set of tasks from the GLUE and SuperGLUE datasets, which may not capture the full range of linguistic diversity in AAVE.
                        </p>
                        <p>
                          Furthermore, while we have employed quantitative metrics to evaluate translation quality, human evaluation by native AAVE speakers could provide deeper insights into the cultural and linguistic appropriateness of the translations.
                        </p>
                      </div>
                    </div>
                  </div>
                </div>
              </section>
              <!-- Ethics Section -->
              <section class="section">
                <div class="container is-max-desktop">
                  <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                      <h2 class="title is-4">Ethical Considerations</h2>
                      <div class="content has-text-justified">
                        <p>
                          Our research is guided by ethical principles that prioritize the respectful and fair treatment of all dialects. By identifying biases in language models, we aim to contribute to the development of more inclusive NLP systems that serve diverse linguistic communities effectively.
                        </p>
                        <p>
                          We have made our code and evaluation methods publicly available to promote transparency and reproducibility, encouraging further research and collaboration in this critical area. The insights gained from our work extend beyond AAVE, highlighting the need for inclusive language technologies across various underrepresented dialects.
                        </p>
                      </div>
                    </div>
                  </div>
                </div>
              </section>
              <!-- Related Works Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Related Works</h2>
        <div class="content has-text-justified">
          <p>
            Our work builds upon several important benchmarks and studies in the field of natural language processing. The <strong><a href="https://arxiv.org/abs/1804.07461" target="_blank">GLUE</a></strong> benchmark provides a platform for evaluating language model performance across a variety of standard linguistic tasks, primarily focusing on Standard American English (SAE). <strong><a href="https://arxiv.org/abs/1905.00537" target="_blank">SuperGLUE</a></strong> extends this by introducing more challenging tasks that require nuanced understanding and reasoning.
          </p>
          <p>
            <strong><a href="https://aclanthology.org/2022.acl-long.258" target="_blank">VALUE</a></strong> (VernAcular Language Understanding Evaluation) addresses dialect disparity in natural language understanding by using a set of linguistic transformation rules to evaluate models on African American Vernacular English (AAVE). However, its deterministic approach can limit generalizability across different contexts.
          </p>
          <p>
            Additionally, studies such as "<a href="https://aclanthology.org/P19-1163" target="_blank">The Risk of Racial Bias in Hate Speech Detection</a>" by Sap et al. and "<a href="https://arxiv.org/abs/2005.14050" target="_blank">Language (Technology) is Power: A Critical Survey of 'Bias' in NLP</a>" by Blodgett et al. have highlighted the biases that exist in language technologies, underscoring the importance of addressing these issues to develop fair and equitable NLP systems.
          </p>
          <p>
            Our benchmark, AAVENUE, seeks to expand upon these foundations by providing a more comprehensive evaluation of dialectal bias, specifically focusing on the performance of large language models in handling tasks in AAVE compared to SAE.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- FAQ Section -->
<section class="section" id="FAQ">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Frequently Asked Questions</h2>

        <!-- FAQ 1 -->
        <div class="faq-item">
          <button class="button is-fullwidth" onclick="toggleFAQ('faq1')">
            <span class="faq-question">What is AAVENUE?</span>
            <span class="icon is-small" id="faq-icon1">
              <i class="fas fa-chevron-down"></i>
            </span>
          </button>
          <div id="faq1" class="faq-answer" style="display:none;">
            <p>AAVENUE (AAVE Natural Language Understanding Evaluation) is a benchmark designed to assess how well large language models handle tasks in African American Vernacular English compared to Standard American English.</p>
          </div>
        </div>

        <!-- FAQ 2 -->
        <div class="faq-item">
          <button class="button is-fullwidth" onclick="toggleFAQ('faq2')">
            <span class="faq-question">How can AAVENUE help reduce biases in NLP?</span>
            <span class="icon is-small" id="faq-icon2">
              <i class="fas fa-chevron-down"></i>
            </span>
          </button>
          <div id="faq2" class="faq-answer" style="display:none;">
            <p>By providing a detailed evaluation of language models on AAVE, AAVENUE helps identify and mitigate biases that might otherwise lead to less effective NLP applications for users of this dialect.</p>
          </div>
        </div>

        <!-- FAQ 3 -->
        <div class="faq-item">
          <button class="button is-fullwidth" onclick="toggleFAQ('faq3')">
            <span class="faq-question">Where can I access the AAVENUE dataset and tools?</span>
            <span class="icon is-small" id="faq-icon3">
              <i class="fas fa-chevron-down"></i>
            </span>
          </button>
          <div id="faq3" class="faq-answer" style="display:none;">
            <p>The tools and datasets developed as part of AAVENUE are publicly available on our GitHub repository for researchers and developers to use and contribute to.</p>
          </div>
        </div>

        <!-- FAQ 4 -->
        <div class="faq-item">
          <button class="button is-fullwidth" onclick="toggleFAQ('faq4')">
            <span class="faq-question">How does AAVENUE compare to other benchmarks?</span>
            <span class="icon is-small" id="faq-icon4">
              <i class="fas fa-chevron-down"></i>
            </span>
          </button>
          <div id="faq4" class="faq-answer" style="display:none;">
            <p>Unlike many traditional benchmarks that primarily focus on SAE, AAVENUE specifically measures performance across dialects, emphasizing the handling of AAVE to spotlight and address disparities in model performance.</p>
          </div>
        </div>

        <!-- FAQ 5 -->
        <div class="faq-item">
          <button class="button is-fullwidth" onclick="toggleFAQ('faq5')">
            <span class="faq-question">Can I contribute to the AAVENUE project?</span>
            <span class="icon is-small" id="faq-icon5">
              <i class="fas fa-chevron-down"></i>
            </span>
          </button>
          <div id="faq5" class="faq-answer" style="display:none;">
            <p>Yes, contributions are welcome! We encourage you to contribute through GitHub, whether it's improving the benchmark, offering new datasets, or providing feedback on the tool.</p>
          </div>
        </div>
        
      </div>
    </div>
  </div>
</section>

<!-- Footer with links and contacts -->
<footer class="footer">
  <div class="container has-text-centered">
    <p>
      <a href="https://github.com/abhayg1266/AAVENUE-Code" class="icon-link">
        <i class="fab fa-github"></i> GitHub Code
      </a>
      &nbsp;|&nbsp;
      <a href="https://drive.google.com/file/d/1IjlfozzvaAGI4q3ZmPJIy1NLgLboItHS/view?usp=sharing" class="icon-link">
        <i class="fas fa-file-pdf"></i> Paper
      </a>
    </p>
    <p>If you have any further questions, feel free to message <a href="https://www.linkedin.com/in/abhaygupta12/">Abhay Gupta</a> on LinkedIn.</p>
  </div>
</footer>
<!-- JavaScript for FAQ toggling -->
<script>
function toggleFAQ(id) {
  var element = document.getElementById(id);
  var icon = document.getElementById('faq-icon' + id.charAt(id.length-1));
  if (element.style.display === 'none') {
    element.style.display = 'block';
    icon.classList.remove('fa-chevron-down');
    icon.classList.add('fa-chevron-up');
  } else {
    element.style.display = 'none';
    icon.classList.remove('fa-chevron-up');
    icon.classList.add('fa-chevron-down');
  }
}
</script>

<div id="footer">
  © 2024 AAVENUE. All Rights Reserved
</div>
